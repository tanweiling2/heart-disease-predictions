{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "acd2a2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ab6be96d-fdd7-4b60-898f-9adc9bedd2ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>stroke</th>\n",
       "      <th>gender_Male</th>\n",
       "      <th>ever_married_Yes</th>\n",
       "      <th>work_type_Never_worked</th>\n",
       "      <th>work_type_Private</th>\n",
       "      <th>work_type_Self-employed</th>\n",
       "      <th>Residence_type_Urban</th>\n",
       "      <th>smoking_status_m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>67.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>228.69</td>\n",
       "      <td>36.6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>105.92</td>\n",
       "      <td>32.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>171.23</td>\n",
       "      <td>34.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>79.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>174.12</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>81.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>186.21</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>74.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>70.09</td>\n",
       "      <td>27.4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>69.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>94.39</td>\n",
       "      <td>22.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>78.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>58.57</td>\n",
       "      <td>24.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>81.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>80.43</td>\n",
       "      <td>29.7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>61.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>120.46</td>\n",
       "      <td>36.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  hypertension  heart_disease  avg_glucose_level   bmi  stroke  \\\n",
       "0  67.0             0              1             228.69  36.6       1   \n",
       "1  80.0             0              1             105.92  32.5       1   \n",
       "2  49.0             0              0             171.23  34.4       1   \n",
       "3  79.0             1              0             174.12  24.0       1   \n",
       "4  81.0             0              0             186.21  29.0       1   \n",
       "5  74.0             1              1              70.09  27.4       1   \n",
       "6  69.0             0              0              94.39  22.8       1   \n",
       "7  78.0             0              0              58.57  24.2       1   \n",
       "8  81.0             1              0              80.43  29.7       1   \n",
       "9  61.0             0              1             120.46  36.8       1   \n",
       "\n",
       "   gender_Male  ever_married_Yes  work_type_Never_worked  work_type_Private  \\\n",
       "0            1                 1                       0                  1   \n",
       "1            1                 1                       0                  1   \n",
       "2            0                 1                       0                  1   \n",
       "3            0                 1                       0                  0   \n",
       "4            1                 1                       0                  1   \n",
       "5            1                 1                       0                  1   \n",
       "6            0                 0                       0                  1   \n",
       "7            0                 1                       0                  1   \n",
       "8            0                 1                       0                  1   \n",
       "9            0                 1                       0                  0   \n",
       "\n",
       "   work_type_Self-employed  Residence_type_Urban  smoking_status_m  \n",
       "0                        0                     1                 1  \n",
       "1                        0                     0                 0  \n",
       "2                        0                     1                 2  \n",
       "3                        1                     0                 0  \n",
       "4                        0                     1                 1  \n",
       "5                        0                     0                 0  \n",
       "6                        0                     1                 0  \n",
       "7                        0                     1                 3  \n",
       "8                        0                     0                 0  \n",
       "9                        0                     0                 2  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stroke_df = pd.read_csv('stroke_dataset.csv')\n",
    "stroke_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b06ee2",
   "metadata": {},
   "source": [
    "## Splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d97e23f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the dataset into test, train and validation\n",
    "# train is 0.8, test is 0.2\n",
    "# validation set is not needed since we are using StratifiedKFold() later on for Cross Validation\n",
    "\n",
    "# feature only dataset: X\n",
    "# target variable only dataset: y\n",
    "X = stroke_df.drop(columns='stroke')\n",
    "y = stroke_df['stroke']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,\n",
    "                                                    random_state=21, shuffle=True, stratify=y)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#scale the feature data using z-score scaling \n",
    "# Fit the scaler only on the training data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Transform test and validation data based on training data scaler\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4423613",
   "metadata": {},
   "source": [
    "## Decision Tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3bc66534",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(class_weight={0: 1, 1: 20}, max_depth=4,\n",
       "                       min_samples_leaf=200, min_samples_split=1000,\n",
       "                       random_state=21)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" checked><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(class_weight={0: 1, 1: 20}, max_depth=4,\n",
       "                       min_samples_leaf=200, min_samples_split=1000,\n",
       "                       random_state=21)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(class_weight={0: 1, 1: 20}, max_depth=4,\n",
       "                       min_samples_leaf=200, min_samples_split=1000,\n",
       "                       random_state=21)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# initiate DT clf with a random guess\n",
    "clf = DecisionTreeClassifier(criterion='gini', \n",
    "                            max_depth=4, \n",
    "                            min_samples_split=1000,\n",
    "                            min_samples_leaf=200,\n",
    "                            class_weight={0: 1, 1: 20},\n",
    "                            random_state=21)\n",
    "\n",
    "\n",
    "clf.fit(X_train_scaled,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "939b9c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier (Untuned) accuracy is 0.66354\n",
      "Decision Tree Classifier (Untuned) AUC score is 0.81783\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.65      0.79       919\n",
      "           1       0.10      0.90      0.19        41\n",
      "\n",
      "    accuracy                           0.66       960\n",
      "   macro avg       0.55      0.78      0.49       960\n",
      "weighted avg       0.96      0.66      0.76       960\n",
      "\n",
      "[[600 319]\n",
      " [  4  37]]\n",
      "The test log-likelihood loss for the DT is 0.5341309846485566\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, confusion_matrix, log_loss\n",
    "\n",
    "\n",
    "y_pred = clf.predict(X_test_scaled)\n",
    "y_pred_proba = clf.predict_proba(X_test_scaled)[:, 1]\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "roc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "print(f\"Decision Tree Classifier (Untuned) accuracy is {acc:.5f}\")\n",
    "print(f\"Decision Tree Classifier (Untuned) AUC score is {roc:.5f}\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"The test log-likelihood loss for the DT is\", log_loss(y_test, y_pred_proba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9b079a1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=21, shuffle=True),\n",
       "             estimator=DecisionTreeClassifier(class_weight={0: 1, 1: 20},\n",
       "                                              max_depth=4, min_samples_leaf=200,\n",
       "                                              min_samples_split=1000,\n",
       "                                              random_state=21),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;],\n",
       "                         &#x27;max_depth&#x27;: array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19]),\n",
       "                         &#x27;min_samples_leaf&#x27;: array([  1, 101, 201, 301, 401, 501, 601, 701, 801, 901]),\n",
       "                         &#x27;min_samples_split&#x27;: array([   2,  102,  202,  302,  402,  502,  602,  702,  802,  902, 1002,\n",
       "       1102, 1202, 1302, 1402, 1502, 1602, 1702, 1802, 1902])},\n",
       "             scoring=&#x27;roc_auc&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=21, shuffle=True),\n",
       "             estimator=DecisionTreeClassifier(class_weight={0: 1, 1: 20},\n",
       "                                              max_depth=4, min_samples_leaf=200,\n",
       "                                              min_samples_split=1000,\n",
       "                                              random_state=21),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;],\n",
       "                         &#x27;max_depth&#x27;: array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19]),\n",
       "                         &#x27;min_samples_leaf&#x27;: array([  1, 101, 201, 301, 401, 501, 601, 701, 801, 901]),\n",
       "                         &#x27;min_samples_split&#x27;: array([   2,  102,  202,  302,  402,  502,  602,  702,  802,  902, 1002,\n",
       "       1102, 1202, 1302, 1402, 1502, 1602, 1702, 1802, 1902])},\n",
       "             scoring=&#x27;roc_auc&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(class_weight={0: 1, 1: 20}, max_depth=4,\n",
       "                       min_samples_leaf=200, min_samples_split=1000,\n",
       "                       random_state=21)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(class_weight={0: 1, 1: 20}, max_depth=4,\n",
       "                       min_samples_leaf=200, min_samples_split=1000,\n",
       "                       random_state=21)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=21, shuffle=True),\n",
       "             estimator=DecisionTreeClassifier(class_weight={0: 1, 1: 20},\n",
       "                                              max_depth=4, min_samples_leaf=200,\n",
       "                                              min_samples_split=1000,\n",
       "                                              random_state=21),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19]),\n",
       "                         'min_samples_leaf': array([  1, 101, 201, 301, 401, 501, 601, 701, 801, 901]),\n",
       "                         'min_samples_split': array([   2,  102,  202,  302,  402,  502,  602,  702,  802,  902, 1002,\n",
       "       1102, 1202, 1302, 1402, 1502, 1602, 1702, 1802, 1902])},\n",
       "             scoring='roc_auc')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cross validation to tune for hyperparameter\n",
    "from sklearn.model_selection import GridSearchCV,cross_val_score, StratifiedKFold\n",
    "\n",
    "# Set up Stratified K-Fold cross-validation (better than KFold for imbalanced data)\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=21)\n",
    "\n",
    "\n",
    "#initiate parameters\n",
    "param_dt = {\n",
    "    'max_depth': np.arange(1, 20, 1),  # Max depth of the tree, start from 1 to avoid zero depth\n",
    "    'min_samples_split': np.arange(2, 2000, 100),  # Min samples required to split an internal node\n",
    "    'min_samples_leaf': np.arange(1, 1000, 100),  # Min samples required to be at a leaf node\n",
    "    'criterion': ['gini', 'entropy']  # Function to measure the quality of a split\n",
    "}\n",
    "\n",
    "#training tuned DT model again\n",
    "grid_clf = GridSearchCV(estimator=clf,param_grid=param_dt, scoring='roc_auc', cv=kfold,n_jobs=-1)\n",
    "grid_clf.fit(X_train_scaled,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d46f4f86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparamaters for the Decision Tree is \n",
      "{'criterion': 'gini', 'max_depth': 3, 'min_samples_leaf': 201, 'min_samples_split': 502}\n"
     ]
    }
   ],
   "source": [
    "clf_best_model = grid_clf.best_params_\n",
    "print(\"Best hyperparamaters for the Decision Tree is \")\n",
    "print(clf_best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "90a72384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation AUC scores for 5 folds:  [0.84634096 0.86293548 0.84470668 0.78451408 0.82992734]\n",
      "Mean cross validation AUC score = 0.834\n",
      "++++++++++++++++++++++++++++++++++++++\n",
      "Test dataset: Decision Tree Classifier (Tuned) accuracy is 0.78125\n",
      "\n",
      "\n",
      "Test dataset: Decision Tree Classifier (Tuned) AUC is 0.83702\n",
      "Train dataset: Decision Tree Classifier (Tuned) AUC is 0.85010\n",
      "======================================\n",
      "Confusion matrix from the tuned DT is:\n",
      "[[718 201]\n",
      " [  9  32]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.78      0.87       919\n",
      "           1       0.14      0.78      0.23        41\n",
      "\n",
      "    accuracy                           0.78       960\n",
      "   macro avg       0.56      0.78      0.55       960\n",
      "weighted avg       0.95      0.78      0.85       960\n",
      "\n",
      "======================================\n",
      "The log-likelihood loss for the DT (after tuning hyperparamaters) from test set is 0.5201818417450778\n",
      "The log-likelihood loss for the DT (after tuning hyperparamaters) from train set is 0.4615697919015618\n"
     ]
    }
   ],
   "source": [
    "# Checking generalisation of the tuned model: data_val\n",
    "clf_tuned = grid_clf.best_estimator_\n",
    "clf_tuned_cv = cross_val_score(clf_tuned, X_train_scaled,y_train, cv=kfold, scoring='roc_auc')\n",
    "print(\"Cross validation AUC scores for 5 folds: \",clf_tuned_cv)\n",
    "print(\"Mean cross validation AUC score =\", round(np.mean(clf_tuned_cv),3))\n",
    "print(\"++++++++++++++++++++++++++++++++++++++\")\n",
    "\n",
    "tuned_y_pred = clf_tuned.predict(X_test_scaled)\n",
    "tuned_y_pred_proba = clf_tuned.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "tuned_y_pred_train = clf_tuned.predict(X_train_scaled)\n",
    "tuned_y_pred_train_proba = clf_tuned.predict_proba(X_train_scaled)[:, 1]\n",
    "\n",
    "clf_tuned_acc = accuracy_score(y_test, tuned_y_pred)\n",
    "print(f\"Test dataset: Decision Tree Classifier (Tuned) accuracy is {clf_tuned_acc:.5f}\")\n",
    "print(\"\\n\")\n",
    "clf_tuned_auc = roc_auc_score(y_test, tuned_y_pred_proba)\n",
    "print(f\"Test dataset: Decision Tree Classifier (Tuned) AUC is {clf_tuned_auc:.5f}\")\n",
    "clf_tuned_train_auc = roc_auc_score(y_train, tuned_y_pred_train_proba)\n",
    "print(f\"Train dataset: Decision Tree Classifier (Tuned) AUC is {clf_tuned_train_auc:.5f}\")\n",
    "print(\"======================================\")\n",
    "\n",
    "#Checking performance on test\n",
    "print(\"Confusion matrix from the tuned DT is:\")\n",
    "print(confusion_matrix(y_test, tuned_y_pred))\n",
    "# Calculate precision and recall\n",
    "print(classification_report(y_test, tuned_y_pred))\n",
    "\n",
    "print(\"======================================\")\n",
    "print(\"The log-likelihood loss for the DT (after tuning hyperparamaters) from test set is\", log_loss(y_test, tuned_y_pred_proba))\n",
    "print(\"The log-likelihood loss for the DT (after tuning hyperparamaters) from train set is\", log_loss(y_train, tuned_y_pred_train_proba))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d606850d",
   "metadata": {},
   "source": [
    "### new scoring metric during gridsearchcv: recall, f1-score and log-loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5741d45f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model performance using scoring: neg_log_loss\n",
      "Fitting 5 folds for each of 7600 candidates, totalling 38000 fits\n",
      "Cross-validation neg_log_loss scores for 5 folds:  [-0.46154643 -0.48289275 -0.46527275 -0.50924015 -0.46451978]\n",
      "Mean cross-validation neg_log_loss score = -0.477\n",
      "\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n",
      "Test Accuracy using the best Decision Tree model: 0.78125\n",
      "Test AUC using the best Decision Tree model: 0.84207\n",
      "Confusion matrix of the Test data:\n",
      "[[718 201]\n",
      " [  9  32]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.78      0.87       919\n",
      "           1       0.14      0.78      0.23        41\n",
      "\n",
      "    accuracy                           0.78       960\n",
      "   macro avg       0.56      0.78      0.55       960\n",
      "weighted avg       0.95      0.78      0.85       960\n",
      "\n",
      "Confusion matrix of the Train data:\n",
      "[[2893  779]\n",
      " [  38  128]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.79      0.88      3672\n",
      "           1       0.14      0.77      0.24       166\n",
      "\n",
      "    accuracy                           0.79      3838\n",
      "   macro avg       0.56      0.78      0.56      3838\n",
      "weighted avg       0.95      0.79      0.85      3838\n",
      "\n",
      "The log-likelihood loss for the Decision Tree (after tuning hyperparameters) from test set is 0.47822382321212126\n",
      "The log-likelihood loss for the Decision Tree (after tuning hyperparameters) from train set is 0.46067872304851587\n",
      "Train neg_log_loss score: 0.46068\n",
      "Test neg_log_loss score: 0.47822\n",
      "\n",
      "====================================\n",
      "\n",
      "Model performance using scoring: f1\n",
      "Fitting 5 folds for each of 7600 candidates, totalling 38000 fits\n",
      "Cross-validation f1 scores for 5 folds:  [0.27       0.25615764 0.24884793 0.19491525 0.22110553]\n",
      "Mean cross-validation f1 score = 0.238\n",
      "\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n",
      "Test Accuracy using the best Decision Tree model: 0.76042\n",
      "Test AUC using the best Decision Tree model: 0.83589\n",
      "Confusion matrix of the Test data:\n",
      "[[697 222]\n",
      " [  8  33]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.76      0.86       919\n",
      "           1       0.13      0.80      0.22        41\n",
      "\n",
      "    accuracy                           0.76       960\n",
      "   macro avg       0.56      0.78      0.54       960\n",
      "weighted avg       0.95      0.76      0.83       960\n",
      "\n",
      "Confusion matrix of the Train data:\n",
      "[[2836  836]\n",
      " [  32  134]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.77      0.87      3672\n",
      "           1       0.14      0.81      0.24       166\n",
      "\n",
      "    accuracy                           0.77      3838\n",
      "   macro avg       0.56      0.79      0.55      3838\n",
      "weighted avg       0.95      0.77      0.84      3838\n",
      "\n",
      "The log-likelihood loss for the Decision Tree (after tuning hyperparameters) from test set is 0.5102244682038902\n",
      "The log-likelihood loss for the Decision Tree (after tuning hyperparameters) from train set is 0.4424457429910449\n",
      "Train f1 score: 0.23592\n",
      "Test f1 score: 0.22297\n",
      "\n",
      "====================================\n",
      "\n",
      "Model performance using scoring: recall\n",
      "Fitting 5 folds for each of 7600 candidates, totalling 38000 fits\n",
      "Cross-validation recall scores for 5 folds:  [0.84848485 0.93939394 1.         0.84848485 0.93939394]\n",
      "Mean cross-validation recall score = 0.915\n",
      "\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n",
      "Test Accuracy using the best Decision Tree model: 0.53438\n",
      "Test AUC using the best Decision Tree model: 0.74515\n",
      "Confusion matrix of the Test data:\n",
      "[[473 446]\n",
      " [  1  40]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.51      0.68       919\n",
      "           1       0.08      0.98      0.15        41\n",
      "\n",
      "    accuracy                           0.53       960\n",
      "   macro avg       0.54      0.75      0.42       960\n",
      "weighted avg       0.96      0.53      0.66       960\n",
      "\n",
      "Confusion matrix of the Train data:\n",
      "[[1932 1740]\n",
      " [   7  159]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.53      0.69      3672\n",
      "           1       0.08      0.96      0.15       166\n",
      "\n",
      "    accuracy                           0.54      3838\n",
      "   macro avg       0.54      0.74      0.42      3838\n",
      "weighted avg       0.96      0.54      0.67      3838\n",
      "\n",
      "The log-likelihood loss for the Decision Tree (after tuning hyperparameters) from test set is 0.5383593510898058\n",
      "The log-likelihood loss for the Decision Tree (after tuning hyperparameters) from train set is 0.5294453036939829\n",
      "Train recall score: 0.95783\n",
      "Test recall score: 0.97561\n",
      "\n",
      "====================================\n",
      "\n",
      "Model performance using scoring: make_scorer(fbeta_score, beta=2)\n",
      "Fitting 5 folds for each of 7600 candidates, totalling 38000 fits\n",
      "Cross-validation make_scorer(fbeta_score, beta=2) scores for 5 folds:  [0.45150502 0.43046358 0.42319749 0.34328358 0.36912752]\n",
      "Mean cross-validation make_scorer(fbeta_score, beta=2) score = 0.404\n",
      "\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n",
      "Test Accuracy using the best Decision Tree model: 0.76042\n",
      "Test AUC using the best Decision Tree model: 0.83589\n",
      "Confusion matrix of the Test data:\n",
      "[[697 222]\n",
      " [  8  33]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.76      0.86       919\n",
      "           1       0.13      0.80      0.22        41\n",
      "\n",
      "    accuracy                           0.76       960\n",
      "   macro avg       0.56      0.78      0.54       960\n",
      "weighted avg       0.95      0.76      0.83       960\n",
      "\n",
      "Confusion matrix of the Train data:\n",
      "[[2836  836]\n",
      " [  32  134]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.77      0.87      3672\n",
      "           1       0.14      0.81      0.24       166\n",
      "\n",
      "    accuracy                           0.77      3838\n",
      "   macro avg       0.56      0.79      0.55      3838\n",
      "weighted avg       0.95      0.77      0.84      3838\n",
      "\n",
      "The log-likelihood loss for the Decision Tree (after tuning hyperparameters) from test set is 0.5102244682038902\n",
      "The log-likelihood loss for the Decision Tree (after tuning hyperparameters) from train set is 0.4424457429910449\n",
      "Train make_scorer(fbeta_score, beta=2) score: 0.41004\n",
      "Test make_scorer(fbeta_score, beta=2) score: 0.39379\n",
      "\n",
      "====================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import make_scorer, fbeta_score, f1_score,  recall_score, f1_score, accuracy_score, roc_auc_score, classification_report, confusion_matrix, log_loss\n",
    "# Define F2 score as a custom scoring metric\n",
    "f2_scorer = make_scorer(fbeta_score, beta=2)\n",
    "\n",
    "# Add 'f2' scoring to the list of metrics\n",
    "scoring_metrics_DT = ['roc_auc','neg_log_loss', 'f1', 'recall', f2_scorer]\n",
    "\n",
    "for scoring in scoring_metrics_DT:\n",
    "    print(f\"Model performance using scoring: {scoring}\")\n",
    "    \n",
    "    # Using GridSearchCV with K-Fold cross-validation to find the best hyperparameters\n",
    "    grid_dt = GridSearchCV(estimator=clf, param_grid=param_dt, \n",
    "                           scoring=scoring, cv=kfold, n_jobs=-1, verbose=1)\n",
    "    grid_dt.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Get the best model from the grid search\n",
    "    tuned_dt = grid_dt.best_estimator_\n",
    "    \n",
    "    # Evaluate using cross-validation on the entire dataset\n",
    "    tuned_dt_cv = cross_val_score(tuned_dt, X_train_scaled, y_train, cv=kfold, scoring=scoring)\n",
    "    print(f\"Cross-validation {scoring} scores for {kfold.get_n_splits()} folds: \", tuned_dt_cv)\n",
    "    print(f\"Mean cross-validation {scoring} score =\", round(np.mean(tuned_dt_cv), 3))\n",
    "    print(\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\n",
    "    \n",
    "    # Predictions on train and test data\n",
    "    tuned_dt_train_pred = tuned_dt.predict(X_train_scaled)\n",
    "    tuned_dt_test_pred = tuned_dt.predict(X_test_scaled)\n",
    "    \n",
    "    # Accuracy\n",
    "    tuned_dt_test_acc = accuracy_score(y_test, tuned_dt_test_pred)\n",
    "    print(f\"Test Accuracy using the best Decision Tree model: {tuned_dt_test_acc:.5f}\")\n",
    "    \n",
    "    # AUC\n",
    "    tuned_dt_test_auc = roc_auc_score(y_test, tuned_dt.predict_proba(X_test_scaled)[:, 1])\n",
    "    print(f\"Test AUC using the best Decision Tree model: {tuned_dt_test_auc:.5f}\")\n",
    "\n",
    "    # Generate and print the classification report\n",
    "    print(\"Confusion matrix of the Test data:\")\n",
    "    print(confusion_matrix(y_test, tuned_dt_test_pred))\n",
    "    print(classification_report(y_test, tuned_dt_test_pred))\n",
    "    print(\"Confusion matrix of the Train data:\")\n",
    "    print(confusion_matrix(y_train, tuned_dt_train_pred))\n",
    "    print(classification_report(y_train, tuned_dt_train_pred))\n",
    "    \n",
    "    #log-loss \n",
    "    print(\"The log-likelihood loss for the Decision Tree (after tuning hyperparameters) from test set is\", log_loss(y_test, tuned_dt.predict_proba(X_test_scaled)))\n",
    "    print(\"The log-likelihood loss for the Decision Tree (after tuning hyperparameters) from train set is\", log_loss(y_train, tuned_dt.predict_proba(X_train_scaled)))\n",
    "    \n",
    "    # Train and test scores for the selected metric\n",
    "    if scoring == 'roc_auc':\n",
    "        train_score = roc_auc_score(y_train, tuned_dt.predict_proba(X_train_scaled)[:, 1])\n",
    "        test_score = roc_auc_score(y_test, tuned_dt.predict_proba(X_test_scaled)[:, 1])\n",
    "    elif scoring == 'f1':\n",
    "        train_score = f1_score(y_train, tuned_dt_train_pred)\n",
    "        test_score = f1_score(y_test, tuned_dt_test_pred)\n",
    "    elif scoring == 'recall':\n",
    "        train_score = recall_score(y_train, tuned_dt_train_pred)\n",
    "        test_score = recall_score(y_test, tuned_dt_test_pred)\n",
    "    elif scoring == f2_scorer:\n",
    "        train_score = fbeta_score(y_train, tuned_dt_train_pred, beta=2)\n",
    "        test_score = fbeta_score(y_test, tuned_dt_test_pred, beta=2)\n",
    "    elif scoring == 'neg_log_loss':\n",
    "        train_score = log_loss(y_train, tuned_dt.predict_proba(X_train_scaled))\n",
    "        test_score = log_loss(y_test, tuned_dt.predict_proba(X_test_scaled))\n",
    "    else:\n",
    "        train_score, test_score = \"N/A\", \"N/A\"\n",
    "        \n",
    "    # Display the train and test scores for the selected scoring metric\n",
    "    print(f\"Train {scoring} score: {train_score:.5f}\" if isinstance(train_score, (float, int)) else f\"{scoring} score could not be calculated for train set.\")\n",
    "    print(f\"Test {scoring} score: {test_score:.5f}\" if isinstance(test_score, (float, int)) else f\"{scoring} score could not be calculated for test set.\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    print(\"\\n====================================\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81061ed0",
   "metadata": {},
   "source": [
    "## Random Forest Classifier (regularisation of DT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "09f70c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tried GridSearchCV and it was taking too long, replaced with RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "72629170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model performance using scoring: roc_auc\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "Cross-validation roc_auc scores for 5 folds:  [0.84028035 0.84836116 0.87542074 0.7897366  0.82614978]\n",
      "Mean cross-validation roc_auc score = 0.836\n",
      "..............................\n",
      "Test Accuracy using the best Random Forest model: 0.80312\n",
      "Test AUC using the best Random Forest model: 0.85756\n",
      "Confusion matrix of the Test data:\n",
      "[[740 179]\n",
      " [ 10  31]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.81      0.89       919\n",
      "           1       0.15      0.76      0.25        41\n",
      "\n",
      "    accuracy                           0.80       960\n",
      "   macro avg       0.57      0.78      0.57       960\n",
      "weighted avg       0.95      0.80      0.86       960\n",
      "\n",
      "Confusion matrix of the Train data:\n",
      "[[3000  672]\n",
      " [  28  138]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.82      0.90      3672\n",
      "           1       0.17      0.83      0.28       166\n",
      "\n",
      "    accuracy                           0.82      3838\n",
      "   macro avg       0.58      0.82      0.59      3838\n",
      "weighted avg       0.96      0.82      0.87      3838\n",
      "\n",
      "The log-likelihood loss for the Random Forest (after tuning hyperparameters) from test set is 0.390410833300828\n",
      "The log-likelihood loss for the Random Forest (after tuning hyperparameters) from train set is 0.36949416943789953\n",
      "Train roc_auc score: 0.90807\n",
      "Test roc_auc score: 0.85756\n",
      "\n",
      "====================================\n",
      "\n",
      "Model performance using scoring: neg_log_loss\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "Cross-validation neg_log_loss scores for 5 folds:  [-0.15599994 -0.15667888 -0.14680597 -0.24672631 -0.19550439]\n",
      "Mean cross-validation neg_log_loss score = -0.18\n",
      "..............................\n",
      "Test Accuracy using the best Random Forest model: 0.95729\n",
      "Test AUC using the best Random Forest model: 0.83995\n",
      "Confusion matrix of the Test data:\n",
      "[[919   0]\n",
      " [ 41   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98       919\n",
      "           1       0.00      0.00      0.00        41\n",
      "\n",
      "    accuracy                           0.96       960\n",
      "   macro avg       0.48      0.50      0.49       960\n",
      "weighted avg       0.92      0.96      0.94       960\n",
      "\n",
      "Confusion matrix of the Train data:\n",
      "[[3672    0]\n",
      " [   0  166]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3672\n",
      "           1       1.00      1.00      1.00       166\n",
      "\n",
      "    accuracy                           1.00      3838\n",
      "   macro avg       1.00      1.00      1.00      3838\n",
      "weighted avg       1.00      1.00      1.00      3838\n",
      "\n",
      "The log-likelihood loss for the Random Forest (after tuning hyperparameters) from test set is 0.1744170518312944\n",
      "The log-likelihood loss for the Random Forest (after tuning hyperparameters) from train set is 0.043746644806796485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/weilingtan/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/weilingtan/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/weilingtan/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train neg_log_loss score: 0.04375\n",
      "Test neg_log_loss score: 0.17442\n",
      "\n",
      "====================================\n",
      "\n",
      "Model performance using scoring: f1\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "Cross-validation f1 scores for 5 folds:  [0.24806202 0.32624113 0.29457364 0.20289855 0.23140496]\n",
      "Mean cross-validation f1 score = 0.261\n",
      "..............................\n",
      "Test Accuracy using the best Random Forest model: 0.87187\n",
      "Test AUC using the best Random Forest model: 0.86430\n",
      "Confusion matrix of the Test data:\n",
      "[[810 109]\n",
      " [ 14  27]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.88      0.93       919\n",
      "           1       0.20      0.66      0.31        41\n",
      "\n",
      "    accuracy                           0.87       960\n",
      "   macro avg       0.59      0.77      0.62       960\n",
      "weighted avg       0.95      0.87      0.90       960\n",
      "\n",
      "Confusion matrix of the Train data:\n",
      "[[3291  381]\n",
      " [  16  150]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.90      0.94      3672\n",
      "           1       0.28      0.90      0.43       166\n",
      "\n",
      "    accuracy                           0.90      3838\n",
      "   macro avg       0.64      0.90      0.69      3838\n",
      "weighted avg       0.96      0.90      0.92      3838\n",
      "\n",
      "The log-likelihood loss for the Random Forest (after tuning hyperparameters) from test set is 0.2873448988058186\n",
      "The log-likelihood loss for the Random Forest (after tuning hyperparameters) from train set is 0.25123050221924653\n",
      "Train f1 score: 0.43042\n",
      "Test f1 score: 0.30508\n",
      "\n",
      "====================================\n",
      "\n",
      "Model performance using scoring: recall\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "Cross-validation recall scores for 5 folds:  [0.84848485 0.84848485 0.91176471 0.72727273 0.78787879]\n",
      "Mean cross-validation recall score = 0.825\n",
      "..............................\n",
      "Test Accuracy using the best Random Forest model: 0.67396\n",
      "Test AUC using the best Random Forest model: 0.83329\n",
      "Confusion matrix of the Test data:\n",
      "[[610 309]\n",
      " [  4  37]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.66      0.80       919\n",
      "           1       0.11      0.90      0.19        41\n",
      "\n",
      "    accuracy                           0.67       960\n",
      "   macro avg       0.55      0.78      0.49       960\n",
      "weighted avg       0.96      0.67      0.77       960\n",
      "\n",
      "Confusion matrix of the Train data:\n",
      "[[2444 1228]\n",
      " [  25  141]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.67      0.80      3672\n",
      "           1       0.10      0.85      0.18       166\n",
      "\n",
      "    accuracy                           0.67      3838\n",
      "   macro avg       0.55      0.76      0.49      3838\n",
      "weighted avg       0.95      0.67      0.77      3838\n",
      "\n",
      "The log-likelihood loss for the Random Forest (after tuning hyperparameters) from test set is 0.5532985913226663\n",
      "The log-likelihood loss for the Random Forest (after tuning hyperparameters) from train set is 0.5525460914690725\n",
      "Train recall score: 0.84940\n",
      "Test recall score: 0.90244\n",
      "\n",
      "====================================\n",
      "\n",
      "Model performance using scoring: make_scorer(fbeta_score, beta=2)\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "Cross-validation make_scorer(fbeta_score, beta=2) scores for 5 folds:  [0.37366548 0.43624161 0.44326241 0.33670034 0.40590406]\n",
      "Mean cross-validation make_scorer(fbeta_score, beta=2) score = 0.399\n",
      "..............................\n",
      "Test Accuracy using the best Random Forest model: 0.80312\n",
      "Test AUC using the best Random Forest model: 0.85756\n",
      "Confusion matrix of the Test data:\n",
      "[[740 179]\n",
      " [ 10  31]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.81      0.89       919\n",
      "           1       0.15      0.76      0.25        41\n",
      "\n",
      "    accuracy                           0.80       960\n",
      "   macro avg       0.57      0.78      0.57       960\n",
      "weighted avg       0.95      0.80      0.86       960\n",
      "\n",
      "Confusion matrix of the Train data:\n",
      "[[3000  672]\n",
      " [  28  138]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.82      0.90      3672\n",
      "           1       0.17      0.83      0.28       166\n",
      "\n",
      "    accuracy                           0.82      3838\n",
      "   macro avg       0.58      0.82      0.59      3838\n",
      "weighted avg       0.96      0.82      0.87      3838\n",
      "\n",
      "The log-likelihood loss for the Random Forest (after tuning hyperparameters) from test set is 0.390410833300828\n",
      "The log-likelihood loss for the Random Forest (after tuning hyperparameters) from train set is 0.36949416943789953\n",
      "Train make_scorer(fbeta_score, beta=2) score: 0.46811\n",
      "Test make_scorer(fbeta_score, beta=2) score: 0.41444\n",
      "\n",
      "====================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, log_loss, fbeta_score, f1_score, recall_score, roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    "# Initiate RandomForestClassifier with class weights for imbalanced data\n",
    "rf = RandomForestClassifier(random_state=21, class_weight={0: 1, 1: 20})\n",
    "\n",
    "# Define the parameter grid for Random Forest\n",
    "param_dt_rf = {\n",
    "    'n_estimators': np.arange(50, 300, 25),  \n",
    "    'max_depth': np.arange(1, 25, 5),  \n",
    "    'min_samples_split': [2, 10, 20, 30],  \n",
    "    'min_samples_leaf': np.arange(1, 20, 5),  \n",
    "    'criterion': ['gini', 'entropy']  \n",
    "}\n",
    "\n",
    "# Define F2 score as a custom scoring metric\n",
    "f2_scorer = make_scorer(fbeta_score, beta=2)\n",
    "\n",
    "# List of scoring metrics\n",
    "scoring_metrics = ['roc_auc', 'neg_log_loss', 'f1', 'recall', f2_scorer]\n",
    "\n",
    "# Loop through different scoring metrics\n",
    "for scoring in scoring_metrics:\n",
    "    print(f\"Model performance using scoring: {scoring}\")\n",
    "    \n",
    "    # Using RandomizedSearchCV to find the best hyperparameters\n",
    "    grid_rf = RandomizedSearchCV(estimator=rf, param_distributions=param_dt_rf, \n",
    "                                 n_iter=100, scoring=scoring, cv=kfold, n_jobs=-1, verbose=1)\n",
    "    grid_rf.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Get the best model from the grid search\n",
    "    tuned_rf = grid_rf.best_estimator_\n",
    "    \n",
    "    # Cross-validation scores for scoring metric\n",
    "    tuned_rf_cv = cross_val_score(tuned_rf, X_train_scaled, y_train, cv=kfold, scoring=scoring)\n",
    "    print(f\"Cross-validation {scoring} scores for {kfold.get_n_splits()} folds: \", tuned_rf_cv)\n",
    "    print(f\"Mean cross-validation {scoring} score =\", round(np.mean(tuned_rf_cv), 3))\n",
    "    print(\"..............................\")\n",
    "\n",
    "    # Predictions on train and test data\n",
    "    tuned_rf_train_pred = tuned_rf.predict(X_train_scaled)\n",
    "    tuned_rf_test_pred = tuned_rf.predict(X_test_scaled)\n",
    "    \n",
    "    # Accuracy\n",
    "    tuned_rf_test_acc = accuracy_score(y_test, tuned_rf_test_pred)\n",
    "    print(f\"Test Accuracy using the best Random Forest model: {tuned_rf_test_acc:.5f}\")\n",
    "    \n",
    "    # AUC\n",
    "    tuned_rf_test_auc = roc_auc_score(y_test, tuned_rf.predict_proba(X_test_scaled)[:, 1])\n",
    "    print(f\"Test AUC using the best Random Forest model: {tuned_rf_test_auc:.5f}\")\n",
    "\n",
    "    # Generate and print the classification report\n",
    "    print(\"Confusion matrix of the Test data:\")\n",
    "    print(confusion_matrix(y_test, tuned_rf_test_pred))\n",
    "    print(classification_report(y_test, tuned_rf_test_pred))\n",
    "    print(\"Confusion matrix of the Train data:\")\n",
    "    print(confusion_matrix(y_train, tuned_rf_train_pred))\n",
    "    print(classification_report(y_train, tuned_rf_train_pred))\n",
    "    \n",
    "    # Log-loss \n",
    "    print(\"The log-likelihood loss for the Random Forest (after tuning hyperparameters) from test set is\", log_loss(y_test, tuned_rf.predict_proba(X_test_scaled)))\n",
    "    print(\"The log-likelihood loss for the Random Forest (after tuning hyperparameters) from train set is\", log_loss(y_train, tuned_rf.predict_proba(X_train_scaled)))\n",
    "    \n",
    "    # Train and test scores for the selected metric\n",
    "    if scoring == 'roc_auc':\n",
    "        train_score = roc_auc_score(y_train, tuned_rf.predict_proba(X_train_scaled)[:, 1])\n",
    "        test_score = roc_auc_score(y_test, tuned_rf.predict_proba(X_test_scaled)[:, 1])\n",
    "    elif scoring == 'f1':\n",
    "        train_score = f1_score(y_train, tuned_rf_train_pred)\n",
    "        test_score = f1_score(y_test, tuned_rf_test_pred)\n",
    "    elif scoring == 'recall':\n",
    "        train_score = recall_score(y_train, tuned_rf_train_pred)\n",
    "        test_score = recall_score(y_test, tuned_rf_test_pred)\n",
    "    elif scoring == f2_scorer:\n",
    "        train_score = fbeta_score(y_train, tuned_rf_train_pred, beta=2)\n",
    "        test_score = fbeta_score(y_test, tuned_rf_test_pred, beta=2)\n",
    "    elif scoring == 'neg_log_loss':\n",
    "        train_score = log_loss(y_train, tuned_rf.predict_proba(X_train_scaled))\n",
    "        test_score = log_loss(y_test, tuned_rf.predict_proba(X_test_scaled))\n",
    "    else:\n",
    "        train_score, test_score = \"N/A\", \"N/A\"\n",
    "        \n",
    "    # Display the train and test scores for the selected scoring metric\n",
    "    print(f\"Train {scoring} score: {train_score:.5f}\" if isinstance(train_score, (float, int)) else f\"{scoring} score could not be calculated for train set.\")\n",
    "    print(f\"Test {scoring} score: {test_score:.5f}\" if isinstance(test_score, (float, int)) else f\"{scoring} score could not be calculated for test set.\")\n",
    "    \n",
    "    print(\"\\n====================================\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33acac1",
   "metadata": {},
   "source": [
    "# Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9feee755",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., ..., 1., 1., 1.])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# since gradient boosting doesn't have a class_weight variable, compute sample_weight variable \n",
    "\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "\n",
    "# Calculate sample weights based on class imbalance\n",
    "sample_weights = compute_sample_weight(class_weight={0: 1, 1: 20}, y=y_train)\n",
    "sample_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "795679cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model performance using scoring: roc_auc\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "Best Gradient Boosting hyperparameters found:  {'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_depth': 3, 'learning_rate': 0.01}\n",
      "Cross-validation roc_auc scores for 5 folds:  [0.83939394 0.8546073  0.84819282 0.77043597 0.83607877]\n",
      "Mean cross-validation roc_auc score = 0.83\n",
      "...........................\n",
      "Test Accuracy using the best Gradient Boosting model: 0.74062\n",
      "Test AUC using the best Gradient Boosting model: 0.84485\n",
      "Confusion matrix of the Test data:\n",
      "[[677 242]\n",
      " [  7  34]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.74      0.84       919\n",
      "           1       0.12      0.83      0.21        41\n",
      "\n",
      "    accuracy                           0.74       960\n",
      "   macro avg       0.56      0.78      0.53       960\n",
      "weighted avg       0.95      0.74      0.82       960\n",
      "\n",
      "Confusion matrix of the Train data:\n",
      "[[2758  914]\n",
      " [  22  144]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.75      0.85      3672\n",
      "           1       0.14      0.87      0.24       166\n",
      "\n",
      "    accuracy                           0.76      3838\n",
      "   macro avg       0.56      0.81      0.55      3838\n",
      "weighted avg       0.96      0.76      0.83      3838\n",
      "\n",
      "The log-likelihood loss for GB (after tuning hyperparameters) from test set is 0.4632726480548578\n",
      "The log-likelihood loss for GB (after tuning hyperparameters) from train set is 0.4415157249687654\n",
      "Train roc_auc score: 0.88728\n",
      "Test roc_auc score: 0.84485\n",
      "\n",
      "====================================\n",
      "\n",
      "Model performance using scoring: neg_log_loss\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "Best Gradient Boosting hyperparameters found:  {'n_estimators': 50, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 10, 'learning_rate': 0.1}\n",
      "Cross-validation neg_log_loss scores for 5 folds:  [-0.24597363 -0.19736003 -0.26484322 -0.25524639 -0.23402303]\n",
      "Mean cross-validation neg_log_loss score = -0.239\n",
      "...........................\n",
      "Test Accuracy using the best Gradient Boosting model: 0.93542\n",
      "Test AUC using the best Gradient Boosting model: 0.80817\n",
      "Confusion matrix of the Test data:\n",
      "[[892  27]\n",
      " [ 35   6]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.97       919\n",
      "           1       0.18      0.15      0.16        41\n",
      "\n",
      "    accuracy                           0.94       960\n",
      "   macro avg       0.57      0.56      0.56       960\n",
      "weighted avg       0.93      0.94      0.93       960\n",
      "\n",
      "Confusion matrix of the Train data:\n",
      "[[3669    3]\n",
      " [   0  166]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3672\n",
      "           1       0.98      1.00      0.99       166\n",
      "\n",
      "    accuracy                           1.00      3838\n",
      "   macro avg       0.99      1.00      1.00      3838\n",
      "weighted avg       1.00      1.00      1.00      3838\n",
      "\n",
      "The log-likelihood loss for GB (after tuning hyperparameters) from test set is 0.17900416903414865\n",
      "The log-likelihood loss for GB (after tuning hyperparameters) from train set is 0.030361850176628728\n",
      "Train neg_log_loss score: 0.03036\n",
      "Test neg_log_loss score: 0.17900\n",
      "\n",
      "====================================\n",
      "\n",
      "Model performance using scoring: f1\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "Best Gradient Boosting hyperparameters found:  {'n_estimators': 100, 'min_samples_split': 20, 'min_samples_leaf': 10, 'max_depth': 5, 'learning_rate': 0.01}\n",
      "Cross-validation f1 scores for 5 folds:  [0. 0. 0. 0. 0.]\n",
      "Mean cross-validation f1 score = 0.0\n",
      "...........................\n",
      "Test Accuracy using the best Gradient Boosting model: 0.79896\n",
      "Test AUC using the best Gradient Boosting model: 0.82070\n",
      "Confusion matrix of the Test data:\n",
      "[[740 179]\n",
      " [ 14  27]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.81      0.88       919\n",
      "           1       0.13      0.66      0.22        41\n",
      "\n",
      "    accuracy                           0.80       960\n",
      "   macro avg       0.56      0.73      0.55       960\n",
      "weighted avg       0.95      0.80      0.86       960\n",
      "\n",
      "Confusion matrix of the Train data:\n",
      "[[3047  625]\n",
      " [  11  155]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.83      0.91      3672\n",
      "           1       0.20      0.93      0.33       166\n",
      "\n",
      "    accuracy                           0.83      3838\n",
      "   macro avg       0.60      0.88      0.62      3838\n",
      "weighted avg       0.96      0.83      0.88      3838\n",
      "\n",
      "The log-likelihood loss for GB (after tuning hyperparameters) from test set is 0.4542820318691561\n",
      "The log-likelihood loss for GB (after tuning hyperparameters) from train set is 0.42377903666653666\n",
      "Train f1 score: 0.32770\n",
      "Test f1 score: 0.21862\n",
      "\n",
      "====================================\n",
      "\n",
      "Model performance using scoring: recall\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "Best Gradient Boosting hyperparameters found:  {'n_estimators': 100, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_depth': 3, 'learning_rate': 0.01}\n",
      "Cross-validation recall scores for 5 folds:  [0. 0. 0. 0. 0.]\n",
      "Mean cross-validation recall score = 0.0\n",
      "...........................\n",
      "Test Accuracy using the best Gradient Boosting model: 0.77812\n",
      "Test AUC using the best Gradient Boosting model: 0.85142\n",
      "Confusion matrix of the Test data:\n",
      "[[716 203]\n",
      " [ 10  31]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.78      0.87       919\n",
      "           1       0.13      0.76      0.23        41\n",
      "\n",
      "    accuracy                           0.78       960\n",
      "   macro avg       0.56      0.77      0.55       960\n",
      "weighted avg       0.95      0.78      0.84       960\n",
      "\n",
      "Confusion matrix of the Train data:\n",
      "[[2898  774]\n",
      " [  35  131]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.79      0.88      3672\n",
      "           1       0.14      0.79      0.24       166\n",
      "\n",
      "    accuracy                           0.79      3838\n",
      "   macro avg       0.57      0.79      0.56      3838\n",
      "weighted avg       0.95      0.79      0.85      3838\n",
      "\n",
      "The log-likelihood loss for GB (after tuning hyperparameters) from test set is 0.4977251762664956\n",
      "The log-likelihood loss for GB (after tuning hyperparameters) from train set is 0.4845901672154552\n",
      "Train recall score: 0.78916\n",
      "Test recall score: 0.75610\n",
      "\n",
      "====================================\n",
      "\n",
      "Model performance using scoring: make_scorer(fbeta_score, beta=2)\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "Best Gradient Boosting hyperparameters found:  {'n_estimators': 50, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_depth': 3, 'learning_rate': 0.01}\n",
      "Cross-validation make_scorer(fbeta_score, beta=2) scores for 5 folds:  [0. 0. 0. 0. 0.]\n",
      "Mean cross-validation make_scorer(fbeta_score, beta=2) score = 0.0\n",
      "...........................\n",
      "Test Accuracy using the best Gradient Boosting model: 0.79063\n",
      "Test AUC using the best Gradient Boosting model: 0.84793\n",
      "Confusion matrix of the Test data:\n",
      "[[728 191]\n",
      " [ 10  31]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.79      0.88       919\n",
      "           1       0.14      0.76      0.24        41\n",
      "\n",
      "    accuracy                           0.79       960\n",
      "   macro avg       0.56      0.77      0.56       960\n",
      "weighted avg       0.95      0.79      0.85       960\n",
      "\n",
      "Confusion matrix of the Train data:\n",
      "[[2960  712]\n",
      " [  38  128]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.81      0.89      3672\n",
      "           1       0.15      0.77      0.25       166\n",
      "\n",
      "    accuracy                           0.80      3838\n",
      "   macro avg       0.57      0.79      0.57      3838\n",
      "weighted avg       0.95      0.80      0.86      3838\n",
      "\n",
      "The log-likelihood loss for GB (after tuning hyperparameters) from test set is 0.5410015023512293\n",
      "The log-likelihood loss for GB (after tuning hyperparameters) from train set is 0.5337140105686055\n",
      "Train make_scorer(fbeta_score, beta=2) score: 0.42553\n",
      "Test make_scorer(fbeta_score, beta=2) score: 0.40155\n",
      "\n",
      "====================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, log_loss, roc_auc_score, f1_score, recall_score, fbeta_score\n",
    "import numpy as np\n",
    "\n",
    "# Initialize the Gradient Boosting Classifier\n",
    "gb = GradientBoostingClassifier(random_state=21)\n",
    "\n",
    "# Define the parameter grid for Gradient Boosting\n",
    "param_dist_gb = {\n",
    "    'n_estimators': [50, 100, 200],  # Number of boosting stages to be run\n",
    "    'learning_rate': [0.01, 0.1, 0.2],  # Shrinks contribution of each tree\n",
    "    'max_depth': [3, 5, 10],  # Maximum depth of the trees\n",
    "    'min_samples_split': [2, 10, 20],  # Minimum samples required to split a node\n",
    "    'min_samples_leaf': [1, 5, 10]  # Minimum number of samples required at a leaf node\n",
    "}\n",
    "\n",
    "# Define custom F2 scoring\n",
    "f2_scorer = make_scorer(fbeta_score, beta=2)\n",
    "\n",
    "# List of scoring metrics\n",
    "scoring_metrics = ['roc_auc', 'neg_log_loss', 'f1', 'recall', f2_scorer]\n",
    "\n",
    "# Loop through different scoring metrics\n",
    "for scoring in scoring_metrics:\n",
    "    print(f\"Model performance using scoring: {scoring}\")\n",
    "    \n",
    "    # Initialize RandomizedSearchCV with cross-validation\n",
    "    random_search_gb = RandomizedSearchCV(estimator=gb, param_distributions=param_dist_gb, \n",
    "                                           n_iter=100, scoring=scoring, cv=kfold, n_jobs=-1, verbose=1, random_state=21)\n",
    "\n",
    "    # Fit the model to the training data\n",
    "    random_search_gb.fit(X_train_scaled, y_train, sample_weight=sample_weights)\n",
    "\n",
    "    # Get the best model from the grid search\n",
    "    best_gb_model = random_search_gb.best_estimator_\n",
    "    print(\"Best Gradient Boosting hyperparameters found: \", random_search_gb.best_params_)\n",
    "    \n",
    "    # Perform cross-validation on the best model\n",
    "    best_gb_model_cv = cross_val_score(best_gb_model, X_train_scaled, y_train, cv=kfold, scoring=scoring)\n",
    "    print(f\"Cross-validation {scoring} scores for {kfold.get_n_splits()} folds: \", best_gb_model_cv)\n",
    "    print(f\"Mean cross-validation {scoring} score =\", round(np.mean(best_gb_model_cv), 3))\n",
    "    print(\"...........................\")\n",
    "\n",
    "    # Predictions on test and train data\n",
    "    y_test_pred_gb = best_gb_model.predict(X_test_scaled)\n",
    "    y_test_pred_gb_proba = best_gb_model.predict_proba(X_test_scaled)[:, 1]\n",
    "    y_train_pred_gb = best_gb_model.predict(X_train_scaled)\n",
    "    y_train_pred_gb_proba = best_gb_model.predict_proba(X_train_scaled)[:, 1]\n",
    "\n",
    "    # Accuracy\n",
    "    gb_accuracy = accuracy_score(y_test, y_test_pred_gb)\n",
    "    print(f\"Test Accuracy using the best Gradient Boosting model: {gb_accuracy:.5f}\")\n",
    "    \n",
    "    # AUC\n",
    "    gb_auc = roc_auc_score(y_test, y_test_pred_gb_proba)\n",
    "    print(f\"Test AUC using the best Gradient Boosting model: {gb_auc:.5f}\")\n",
    "\n",
    "    # Generate and print the classification report\n",
    "    print(\"Confusion matrix of the Test data:\")\n",
    "    print(confusion_matrix(y_test, y_test_pred_gb))\n",
    "    print(classification_report(y_test, y_test_pred_gb))\n",
    "    print(\"Confusion matrix of the Train data:\")\n",
    "    print(confusion_matrix(y_train, y_train_pred_gb))\n",
    "    print(classification_report(y_train, y_train_pred_gb))\n",
    "\n",
    "    # Log-loss\n",
    "    print(\"The log-likelihood loss for GB (after tuning hyperparameters) from test set is\", log_loss(y_test, y_test_pred_gb_proba))\n",
    "    print(\"The log-likelihood loss for GB (after tuning hyperparameters) from train set is\", log_loss(y_train, y_train_pred_gb_proba))\n",
    "\n",
    "    # Train and test scores for the selected metric\n",
    "    if scoring == 'roc_auc':\n",
    "        train_score = roc_auc_score(y_train, y_train_pred_gb_proba)\n",
    "        test_score = roc_auc_score(y_test, y_test_pred_gb_proba)\n",
    "    elif scoring == 'f1':\n",
    "        train_score = f1_score(y_train, y_train_pred_gb)\n",
    "        test_score = f1_score(y_test, y_test_pred_gb)\n",
    "    elif scoring == 'recall':\n",
    "        train_score = recall_score(y_train, y_train_pred_gb)\n",
    "        test_score = recall_score(y_test, y_test_pred_gb)\n",
    "    elif scoring == f2_scorer:\n",
    "        train_score = fbeta_score(y_train, y_train_pred_gb, beta=2)\n",
    "        test_score = fbeta_score(y_test, y_test_pred_gb, beta=2)\n",
    "    elif scoring == 'neg_log_loss':\n",
    "        train_score = log_loss(y_train, y_train_pred_gb_proba)\n",
    "        test_score = log_loss(y_test, y_test_pred_gb_proba)\n",
    "    else:\n",
    "        train_score, test_score = \"N/A\", \"N/A\"\n",
    "\n",
    "    # Display the train and test scores for the selected scoring metric\n",
    "    print(f\"Train {scoring} score: {train_score:.5f}\" if isinstance(train_score, (float, int)) else f\"{scoring} score could not be calculated for train set.\")\n",
    "    print(f\"Test {scoring} score: {test_score:.5f}\" if isinstance(test_score, (float, int)) else f\"{scoring} score could not be calculated for test set.\")\n",
    "    \n",
    "    print(\"\\n====================================\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac1cda4",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b87855c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in /Users/weilingtan/opt/anaconda3/lib/python3.9/site-packages (2.1.2)\r\n",
      "Requirement already satisfied: numpy in /Users/weilingtan/opt/anaconda3/lib/python3.9/site-packages (from xgboost) (1.24.4)\r\n",
      "Requirement already satisfied: scipy in /Users/weilingtan/opt/anaconda3/lib/python3.9/site-packages (from xgboost) (1.9.1)\r\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install xgboost\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "34085703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 95.52%\n",
      "0.02699748024615316\n",
      "1.547052691011334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/weilingtan/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [23:23:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "xgb_clf = XGBClassifier(objective='binary:logistic', eval_metric='logloss', use_label_encoder=False)\n",
    "\n",
    "# Train the model\n",
    "xgb_clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = xgb_clf.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy * 100))\n",
    "train_y_pred = xgb_clf.predict(X_train_scaled)\n",
    "print(log_loss(y_train,train_y_pred))\n",
    "print(log_loss(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "863f643b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model performance using scoring: neg_log_loss\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "Best XGBoost hyperparameters found:  {'subsample': 0.7, 'n_estimators': 100, 'max_depth': 10, 'learning_rate': 0.1, 'colsample_bytree': 0.7}\n",
      "Cross-validation neg_log_loss scores for 5 folds:  [-0.17869777 -0.17333059 -0.18299881 -0.22116433 -0.17331334]\n",
      "Mean cross-validation neg_log_loss score = -0.186\n",
      "____________________\n",
      "Test Accuracy using the best XGBoost model: 0.94479\n",
      "Test AUC using the best XGBoost model: 0.82505\n",
      "Confusion matrix of the Test data:\n",
      "[[901  18]\n",
      " [ 35   6]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97       919\n",
      "           1       0.25      0.15      0.18        41\n",
      "\n",
      "    accuracy                           0.94       960\n",
      "   macro avg       0.61      0.56      0.58       960\n",
      "weighted avg       0.93      0.94      0.94       960\n",
      "\n",
      "Confusion matrix of the Train data:\n",
      "[[3668    4]\n",
      " [   0  166]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3672\n",
      "           1       0.98      1.00      0.99       166\n",
      "\n",
      "    accuracy                           1.00      3838\n",
      "   macro avg       0.99      1.00      0.99      3838\n",
      "weighted avg       1.00      1.00      1.00      3838\n",
      "\n",
      "The log-likelihood loss for XGBoost (after tuning hyperparameters) from test set is 0.1664098736826721\n",
      "The log-likelihood loss for XGBoost (after tuning hyperparameters) from training set is 0.03252455716382859\n",
      "Train neg_log_loss score: 0.03252\n",
      "Test neg_log_loss score: 0.16641\n",
      "\n",
      "====================================\n",
      "\n",
      "Model performance using scoring: roc_auc\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "Best XGBoost hyperparameters found:  {'subsample': 0.8, 'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.01, 'colsample_bytree': 0.7}\n",
      "Cross-validation roc_auc scores for 5 folds:  [0.85005154 0.85602968 0.85544558 0.78313104 0.8347783 ]\n",
      "Mean cross-validation roc_auc score = 0.836\n",
      "____________________\n",
      "Test Accuracy using the best XGBoost model: 0.77500\n",
      "Test AUC using the best XGBoost model: 0.85185\n",
      "Confusion matrix of the Test data:\n",
      "[[711 208]\n",
      " [  8  33]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.77      0.87       919\n",
      "           1       0.14      0.80      0.23        41\n",
      "\n",
      "    accuracy                           0.78       960\n",
      "   macro avg       0.56      0.79      0.55       960\n",
      "weighted avg       0.95      0.78      0.84       960\n",
      "\n",
      "Confusion matrix of the Train data:\n",
      "[[2903  769]\n",
      " [  27  139]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.79      0.88      3672\n",
      "           1       0.15      0.84      0.26       166\n",
      "\n",
      "    accuracy                           0.79      3838\n",
      "   macro avg       0.57      0.81      0.57      3838\n",
      "weighted avg       0.95      0.79      0.85      3838\n",
      "\n",
      "The log-likelihood loss for XGBoost (after tuning hyperparameters) from test set is 0.5020952027601501\n",
      "The log-likelihood loss for XGBoost (after tuning hyperparameters) from training set is 0.4914968956325935\n",
      "Train roc_auc score: 0.87798\n",
      "Test roc_auc score: 0.85185\n",
      "\n",
      "====================================\n",
      "\n",
      "Model performance using scoring: f1\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "Best XGBoost hyperparameters found:  {'subsample': 0.7, 'n_estimators': 100, 'max_depth': 7, 'learning_rate': 0.01, 'colsample_bytree': 0.8}\n",
      "Cross-validation f1 scores for 5 folds:  [0.26548673 0.28985507 0.25225225 0.14173228 0.24793388]\n",
      "Mean cross-validation f1 score = 0.239\n",
      "____________________\n",
      "Test Accuracy using the best XGBoost model: 0.86771\n",
      "Test AUC using the best XGBoost model: 0.84429\n",
      "Confusion matrix of the Test data:\n",
      "[[812 107]\n",
      " [ 20  21]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.88      0.93       919\n",
      "           1       0.16      0.51      0.25        41\n",
      "\n",
      "    accuracy                           0.87       960\n",
      "   macro avg       0.57      0.70      0.59       960\n",
      "weighted avg       0.94      0.87      0.90       960\n",
      "\n",
      "Confusion matrix of the Train data:\n",
      "[[3342  330]\n",
      " [   3  163]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.91      0.95      3672\n",
      "           1       0.33      0.98      0.49       166\n",
      "\n",
      "    accuracy                           0.91      3838\n",
      "   macro avg       0.66      0.95      0.72      3838\n",
      "weighted avg       0.97      0.91      0.93      3838\n",
      "\n",
      "The log-likelihood loss for XGBoost (after tuning hyperparameters) from test set is 0.3985067936436584\n",
      "The log-likelihood loss for XGBoost (after tuning hyperparameters) from training set is 0.3681587618991632\n",
      "Train f1 score: 0.49469\n",
      "Test f1 score: 0.24852\n",
      "\n",
      "====================================\n",
      "\n",
      "Model performance using scoring: recall\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "Best XGBoost hyperparameters found:  {'subsample': 1.0, 'n_estimators': 200, 'max_depth': 3, 'learning_rate': 0.01, 'colsample_bytree': 1.0}\n",
      "Cross-validation recall scores for 5 folds:  [0.84848485 0.75757576 0.79411765 0.63636364 0.63636364]\n",
      "Mean cross-validation recall score = 0.735\n",
      "____________________\n",
      "Test Accuracy using the best XGBoost model: 0.75729\n",
      "Test AUC using the best XGBoost model: 0.85591\n",
      "Confusion matrix of the Test data:\n",
      "[[694 225]\n",
      " [  8  33]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.76      0.86       919\n",
      "           1       0.13      0.80      0.22        41\n",
      "\n",
      "    accuracy                           0.76       960\n",
      "   macro avg       0.56      0.78      0.54       960\n",
      "weighted avg       0.95      0.76      0.83       960\n",
      "\n",
      "Confusion matrix of the Train data:\n",
      "[[2840  832]\n",
      " [  26  140]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.77      0.87      3672\n",
      "           1       0.14      0.84      0.25       166\n",
      "\n",
      "    accuracy                           0.78      3838\n",
      "   macro avg       0.57      0.81      0.56      3838\n",
      "weighted avg       0.95      0.78      0.84      3838\n",
      "\n",
      "The log-likelihood loss for XGBoost (after tuning hyperparameters) from test set is 0.46994389987085017\n",
      "The log-likelihood loss for XGBoost (after tuning hyperparameters) from training set is 0.45017555608972715\n",
      "Train recall score: 0.84337\n",
      "Test recall score: 0.80488\n",
      "\n",
      "====================================\n",
      "\n",
      "Model performance using scoring: make_scorer(fbeta_score, beta=2)\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "Best XGBoost hyperparameters found:  {'subsample': 0.7, 'n_estimators': 200, 'max_depth': 3, 'learning_rate': 0.01, 'colsample_bytree': 0.7}\n",
      "Cross-validation make_scorer(fbeta_score, beta=2) scores for 5 folds:  [0.40983607 0.39808917 0.40540541 0.33232628 0.35947712]\n",
      "Mean cross-validation make_scorer(fbeta_score, beta=2) score = 0.381\n",
      "____________________\n",
      "Test Accuracy using the best XGBoost model: 0.76250\n",
      "Test AUC using the best XGBoost model: 0.84915\n",
      "Confusion matrix of the Test data:\n",
      "[[699 220]\n",
      " [  8  33]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.76      0.86       919\n",
      "           1       0.13      0.80      0.22        41\n",
      "\n",
      "    accuracy                           0.76       960\n",
      "   macro avg       0.56      0.78      0.54       960\n",
      "weighted avg       0.95      0.76      0.83       960\n",
      "\n",
      "Confusion matrix of the Train data:\n",
      "[[2894  778]\n",
      " [  27  139]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.79      0.88      3672\n",
      "           1       0.15      0.84      0.26       166\n",
      "\n",
      "    accuracy                           0.79      3838\n",
      "   macro avg       0.57      0.81      0.57      3838\n",
      "weighted avg       0.95      0.79      0.85      3838\n",
      "\n",
      "The log-likelihood loss for XGBoost (after tuning hyperparameters) from test set is 0.46255966456762204\n",
      "The log-likelihood loss for XGBoost (after tuning hyperparameters) from training set is 0.44172660959083754\n",
      "Train make_scorer(fbeta_score, beta=2) score: 0.43960\n",
      "Test make_scorer(fbeta_score, beta=2) score: 0.39568\n",
      "\n",
      "====================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.model_selection import RandomizedSearchCV, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, log_loss, roc_auc_score, f1_score, recall_score, fbeta_score\n",
    "import numpy as np\n",
    "\n",
    "# Calculate class weights\n",
    "class_weights = compute_class_weight(class_weight={0: 1, 1: 20}, classes=np.array([0, 1]), y=y_train)\n",
    "scale_pos_weight = class_weights[1] / class_weights[0]\n",
    "\n",
    "# Define parameter grid for XGBoost\n",
    "param_dist_xgb = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3, 5, 7, 10],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'subsample': [0.7, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.7, 0.8, 1.0]\n",
    "}\n",
    "\n",
    "# Define custom F2 scoring\n",
    "f2_scorer = make_scorer(fbeta_score, beta=2)\n",
    "\n",
    "# List of scoring metrics\n",
    "scoring_metrics = ['neg_log_loss', 'roc_auc', 'f1', 'recall', f2_scorer]\n",
    "\n",
    "# Loop through different scoring metrics\n",
    "for scoring in scoring_metrics:\n",
    "    print(f\"Model performance using scoring: {scoring}\")\n",
    "\n",
    "    # Initialize the XGBClassifier with scale_pos_weight\n",
    "    xgb_clf = XGBClassifier(objective='binary:logistic', eval_metric='logloss', \n",
    "                             scale_pos_weight=scale_pos_weight)\n",
    "\n",
    "    # Initialize RandomizedSearchCV\n",
    "    random_search_xgb = RandomizedSearchCV(estimator=xgb_clf, param_distributions=param_dist_xgb,\n",
    "                                           n_iter=100, scoring=scoring, cv=kfold, n_jobs=-1, verbose=1, random_state=21)\n",
    "\n",
    "    # Fit the model\n",
    "    random_search_xgb.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # Get the best parameters and model\n",
    "    best_xgb_model = random_search_xgb.best_estimator_\n",
    "    print(\"Best XGBoost hyperparameters found: \", random_search_xgb.best_params_)\n",
    "    \n",
    "    # Perform cross-validation on the best model\n",
    "    best_xgb_model_cv = cross_val_score(best_xgb_model, X_train_scaled, y_train, cv=kfold, scoring=scoring)\n",
    "    print(f\"Cross-validation {scoring} scores for {kfold.get_n_splits()} folds: \", best_xgb_model_cv)\n",
    "    print(f\"Mean cross-validation {scoring} score =\", round(np.mean(best_xgb_model_cv), 3))\n",
    "    print(\"____________________\")\n",
    "\n",
    "    # Predict on the test and training data\n",
    "    y_test_pred_xgb = best_xgb_model.predict(X_test_scaled)\n",
    "    y_test_pred_xgb_proba = best_xgb_model.predict_proba(X_test_scaled)[:, 1]\n",
    "    y_train_pred_xgb = best_xgb_model.predict(X_train_scaled)\n",
    "    y_train_pred_xgb_proba = best_xgb_model.predict_proba(X_train_scaled)[:, 1]\n",
    "    \n",
    "    # Accuracy on test data\n",
    "    xgb_accuracy = accuracy_score(y_test, y_test_pred_xgb)\n",
    "    print(f\"Test Accuracy using the best XGBoost model: {xgb_accuracy:.5f}\")\n",
    "    \n",
    "    # AUC on test data\n",
    "    xgb_auc = roc_auc_score(y_test, y_test_pred_xgb_proba)\n",
    "    print(f\"Test AUC using the best XGBoost model: {xgb_auc:.5f}\")\n",
    "\n",
    "    # Classification report and confusion matrix\n",
    "    print(\"Confusion matrix of the Test data:\")\n",
    "    print(confusion_matrix(y_test, y_test_pred_xgb))\n",
    "    print(classification_report(y_test, y_test_pred_xgb))\n",
    "    print(\"Confusion matrix of the Train data:\")\n",
    "    print(confusion_matrix(y_train, y_train_pred_xgb))\n",
    "    print(classification_report(y_train, y_train_pred_xgb))\n",
    "\n",
    "    # Log-loss for both test and training data\n",
    "    print(\"The log-likelihood loss for XGBoost (after tuning hyperparameters) from test set is\", log_loss(y_test, y_test_pred_xgb_proba))\n",
    "    print(\"The log-likelihood loss for XGBoost (after tuning hyperparameters) from training set is\", log_loss(y_train, y_train_pred_xgb_proba))\n",
    "\n",
    "    # Calculate train and test scores for the selected scoring metric\n",
    "    if scoring == 'roc_auc':\n",
    "        train_score = roc_auc_score(y_train, y_train_pred_xgb_proba)\n",
    "        test_score = roc_auc_score(y_test, y_test_pred_xgb_proba)\n",
    "    elif scoring == 'f1':\n",
    "        train_score = f1_score(y_train, y_train_pred_xgb)\n",
    "        test_score = f1_score(y_test, y_test_pred_xgb)\n",
    "    elif scoring == 'recall':\n",
    "        train_score = recall_score(y_train, y_train_pred_xgb)\n",
    "        test_score = recall_score(y_test, y_test_pred_xgb)\n",
    "    elif scoring == f2_scorer:\n",
    "        train_score = fbeta_score(y_train, y_train_pred_xgb, beta=2)\n",
    "        test_score = fbeta_score(y_test, y_test_pred_xgb, beta=2)\n",
    "    elif scoring == 'neg_log_loss':\n",
    "        train_score = log_loss(y_train, y_train_pred_xgb_proba)\n",
    "        test_score = log_loss(y_test, y_test_pred_xgb_proba)\n",
    "    else:\n",
    "        train_score, test_score = \"N/A\", \"N/A\"\n",
    "\n",
    "    # Display train and test scores for the selected scoring metric\n",
    "    print(f\"Train {scoring} score: {train_score:.5f}\" if isinstance(train_score, (float, int)) else f\"{scoring} score could not be calculated for train set.\")\n",
    "    print(f\"Test {scoring} score: {test_score:.5f}\" if isinstance(test_score, (float, int)) else f\"{scoring} score could not be calculated for test set.\")\n",
    "    \n",
    "    print(\"\\n====================================\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd61bd03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
